import pandas as pd
import requests
from bs4 import BeautifulSoup
import json
import time

# CSVã‹ã‚‰éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿
df = pd.read_csv("data/jpx.csv", encoding="utf-8-sig")
codes = df["ã‚³ãƒ¼ãƒ‰"].dropna().astype(str).str.zfill(4).tolist()

# çµæœæ ¼ç´
results = []

for i, code in enumerate(codes[:50]):  # ğŸ”¸æœ€åˆã¯ãƒ†ã‚¹ãƒˆçš„ã«50ä»¶ã ã‘
    url = f"https://irbank.net/{code}"
    headers = { "User-Agent": "Mozilla/5.0" }
    try:
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.content, "html.parser")
        h1 = soup.find("h1")
        name = h1.text.strip() if h1 else ""
        if name:
            results.append({ "code": code, "name": name })
            print(f"{code}: {name}")
    except Exception as e:
        print(f"âš ï¸ {code} ã‚¨ãƒ©ãƒ¼: {e}")
    
    time.sleep(1)  # ã‚¢ã‚¯ã‚»ã‚¹é–“éš”åˆ¶å¾¡

# ä¿å­˜
with open("data/stocks.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)
